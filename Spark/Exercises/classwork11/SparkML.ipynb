{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XOKdw1KsGS9"
   },
   "source": [
    "# Setting up Spark\n",
    "\n",
    "The first section is preparing the notebook for running Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/29 20:37:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/zulu8.78.0.19-ca-jdk8.0.412-linux_aarch64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://rpi0:7077\") \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "If8PJn2jtKAu"
   },
   "source": [
    "The next steps prepares a Spark session and the Spark context needed to use Spark. If you have not done so yet, you have to install the Python package \"findspark\". Do so by running pip on your own machine (not in this notebook): pip3 install findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h89Y5s8LuKtg"
   },
   "source": [
    "# Exercise\n",
    "\n",
    "You are now ready to run the actual exercise.  \n",
    "\n",
    "The dataset describes characteristics of irises. We modified the dataset by reducing it to two types, so we can run a logicistic regression: Iris-versicolor and Iris-virginica. Additional information about this dataset can be found here: <br>\n",
    "https://en.wikipedia.org/wiki/Iris_flower_data_set <br>\n",
    "https://archive.ics.uci.edu/ml/datasets/Iris\n",
    "\n",
    "\n",
    "The columns have the following meanings (label = 1 means the flower is an Iris-versicolor, label = 0 means it is an Iris-virginica):\n",
    "\n",
    "| column | description |\n",
    "| --- | --- |\n",
    "| sl: | sepal length in cm |\n",
    "| sw: | sepal width in cm |\n",
    "| pl: | petal length in cm |\n",
    "| pw: | petal width in cm |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TrGGQLsLrSg8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----+\n",
      "| sl| sw| pl| pw|label|\n",
      "+---+---+---+---+-----+\n",
      "|7.0|3.2|4.7|1.4|    1|\n",
      "|6.4|3.2|4.5|1.5|    1|\n",
      "|6.9|3.1|4.9|1.5|    1|\n",
      "|5.5|2.3|4.0|1.3|    1|\n",
      "|6.5|2.8|4.6|1.5|    1|\n",
      "|5.7|2.8|4.5|1.3|    1|\n",
      "|6.3|3.3|4.7|1.6|    1|\n",
      "|4.9|2.4|3.3|1.0|    1|\n",
      "|6.6|2.9|4.6|1.3|    1|\n",
      "|5.2|2.7|3.9|1.4|    1|\n",
      "|5.0|2.0|3.5|1.0|    1|\n",
      "|5.9|3.0|4.2|1.5|    1|\n",
      "|6.0|2.2|4.0|1.0|    1|\n",
      "|6.1|2.9|4.7|1.4|    1|\n",
      "|5.6|2.9|3.6|1.3|    1|\n",
      "|6.7|3.1|4.4|1.4|    1|\n",
      "|5.6|3.0|4.5|1.5|    1|\n",
      "|5.8|2.7|4.1|1.0|    1|\n",
      "|6.2|2.2|4.5|1.5|    1|\n",
      "|5.6|2.5|3.9|1.1|    1|\n",
      "+---+---+---+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv('hdfs://rpi0:8020/data/iris.csv', header=True, inferSchema=True)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSBDsg6RH-MP"
   },
   "source": [
    "We start by building a pipeline consisting of feature selection (via RFormula) and a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple\n",
      "Requirement already satisfied: numpy in ./myjupyterenv/lib/python3.11/site-packages (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1652770439146,
     "user": {
      "displayName": "Sven Helmer",
      "userId": "02171420419306565957"
     },
     "user_tz": -120
    },
    "id": "QW50IhVmrShE"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "rForm = RFormula()\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rForm, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFiLd1PjIOeG"
   },
   "source": [
    "As the tuning of a model boils down to trying out a lot of different parameters, we use a grid search to do an exhaustive search of all parameter combinations we specify. After running the whole notebook, come back to this section and modify the formulas to find a better model.\n",
    "\n",
    "For a brief introduction to RFormula, go to  \n",
    "https://www.datacamp.com/tutorial/r-formula-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1652770441869,
     "user": {
      "displayName": "Sven Helmer",
      "userId": "02171420419306565957"
     },
     "user_tz": -120
    },
    "id": "nXyOeWlDrShJ"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "params = ParamGridBuilder().addGrid(rForm.formula, [\"label ~ sl\", \"label ~ sw\", \"label ~ pl\", \"label ~ pw\"]).addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]).addGrid(lr.regParam, [0.1,2.0]).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a-dDJSeJF8C"
   },
   "source": [
    "We need to evaluate the performance of the model. As we use logistic regression, we need to be able to evaluate a binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1652770443874,
     "user": {
      "displayName": "Sven Helmer",
      "userId": "02171420419306565957"
     },
     "user_tz": -120
    },
    "id": "ibvXDeKRrShJ"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderPR\", rawPredictionCol=\"prediction\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkpiXwx0JVcX"
   },
   "source": [
    "Using the test dataset during tuning risks of overfitting a model to the test dataset. We only use the test dataset at the very end to evaluate the final model. For model tuning we use a validation dataset (with cross-validation). This is also useful for small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1652770446638,
     "user": {
      "displayName": "Sven Helmer",
      "userId": "02171420419306565957"
     },
     "user_tz": -120
    },
    "id": "dC6SHuqTrShJ"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "\n",
    "tvs = TrainValidationSplit().setTrainRatio(0.75).setEstimatorParamMaps(params).setEstimator(pipeline).setEvaluator(evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iizzbWMDJ76k"
   },
   "source": [
    "Finally, we can do the training of the actual model and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 15765,
     "status": "ok",
     "timestamp": 1652770464294,
     "user": {
      "displayName": "Sven Helmer",
      "userId": "02171420419306565957"
     },
     "user_tz": -120
    },
    "id": "eLIuNdoerShK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train, test = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "tvsFitted = tvs.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2Xe-mHoNrShK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9822580645161291"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(tvsFitted.transform(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrZjrglFKCHI"
   },
   "source": [
    "We can have a closer look at the best model found during the training and access its parameters to see which parameter set came out on top. Go back to the section with the grid search and try to find a parameter set which gives a better evaluation result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AxASVgO_rShL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.684616277801305, 0.4649861276066079, 0.45283915294315713, 0.4518109068746574, 0.4517975493415185, 0.4517975361625189, 0.4517975361617237]\n",
      "[-1.7299045386027792]\n",
      "{Param(parent='LogisticRegression_be0cb8c7c199', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 2, Param(parent='LogisticRegression_be0cb8c7c199', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_be0cb8c7c199', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'): 'auto', Param(parent='LogisticRegression_be0cb8c7c199', name='featuresCol', doc='features column name.'): 'features', Param(parent='LogisticRegression_be0cb8c7c199', name='fitIntercept', doc='whether to fit an intercept term.'): True, Param(parent='LogisticRegression_be0cb8c7c199', name='labelCol', doc='label column name.'): 'label', Param(parent='LogisticRegression_be0cb8c7c199', name='maxBlockSizeInMB', doc='maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0.'): 0.0, Param(parent='LogisticRegression_be0cb8c7c199', name='maxIter', doc='max number of iterations (>= 0).'): 100, Param(parent='LogisticRegression_be0cb8c7c199', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='LogisticRegression_be0cb8c7c199', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability', Param(parent='LogisticRegression_be0cb8c7c199', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction', Param(parent='LogisticRegression_be0cb8c7c199', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_be0cb8c7c199', name='standardization', doc='whether to standardize the training features before fitting the model.'): True, Param(parent='LogisticRegression_be0cb8c7c199', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5, Param(parent='LogisticRegression_be0cb8c7c199', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'label ~ pl'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.feature import RFormulaModel\n",
    "\n",
    "trainedPipeline = tvsFitted.bestModel\n",
    "trainedLRFeat = trainedPipeline.stages[0]\n",
    "trainedLRModel = trainedPipeline.stages[1]\n",
    "\n",
    "print(trainedLRModel.summary.objectiveHistory)\n",
    "print(trainedLRModel.coefficients)\n",
    "print(trainedLRModel.extractParamMap())\n",
    "print(\"\\n\")\n",
    "\n",
    "trainedLRFeat.getFormula()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SparkML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
